{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Elasticsearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "os.environ[\"RABBITMQ_HOST\"] = \"localhost\"\n",
    "\n",
    "from celery_tasks import ingest_data\n",
    "\n",
    "CHUNK_SIZE = 400\n",
    "ES_CHUNK_SIZE = 1000\n",
    "INDEX_NAME = \"es_tripadvisor_nyc_idx\"\n",
    "MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "MODEL_ID_ES = \"sentence-transformers__all-minilm-l6-v2\"\n",
    "MODEL_DIM = 384\n",
    "MODEL_SIMILARITY = \"dot_product\"\n",
    "\n",
    "ES_HOST = \"https://localhost:9200/\"\n",
    "ES_PASS = \"y5AADXZR0l63CvTz1AsWznNiAM1Ukq7KSd3MEra\"\n",
    "COHERE_API_KEY = \"9DUothnkQyEhX9NW7Jr5lr7XsugovOuzYhptkMai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070 with Max-Q Design'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    # For local development\n",
    "    hosts=[ES_HOST],\n",
    "    basic_auth=('elastic', ES_PASS), \n",
    "    verify_certs=False\n",
    ")\n",
    "print(client.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model from hugging face\n",
    "\n",
    "The first thing you will need is a model to create the text embeddings out of the chunks, you can use whatever you would like, but this example will run end to end on the minilm-l6-v2 model. With an Elastic Cloud cluster created or another Elasticsearch cluster ready, we can upload the text embedding model using the eland library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eland_import_hub_model \\\n",
    "    -u elastic -p $ES_PASS \\\n",
    "    --url $ES_HOST \\\n",
    "    --hub-model-id $MODEL_ID \\\n",
    "    --task-type text_embedding \\\n",
    "    --insecure \\\n",
    "    --clear-previous \\\n",
    "    --start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk and Infer in pipeline\n",
    "\n",
    "The next step is to define an ingest pipeline to break up the text field into chunks of text stored in the passages field. This pipeline has two processors, the first script processor breaks up the text field into an array of sentences stored in the passages field via a regular expression. For further research read up on regular expression advanced features such as negative lookbehind and positive lookbehind to understand how it tries to properly split on sentence boundaries, not split on Mr. or Mrs. or Ms., and keep the punctuation with the sentence. It also tries to concatenate the sentence chunks back together as long as the total string length is under the parameter passed to the script. The next for each processor runs the text embedding model on each sentence via an inference processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the pipeline\n",
    "client.ingest.put_pipeline(\n",
    "    id=\"chunk_text_to_passages\",\n",
    "    processors=[\n",
    "        {\n",
    "            \"script\": {\n",
    "                \"description\": \"Chunk body_content into sentences by looking for . followed by a space\",\n",
    "                \"lang\": \"painless\",\n",
    "                \"source\": \"\"\"\n",
    "          String[] envSplit = /((?<!M(r|s|rs)\\.)(?<=\\.) |(?<=\\!) |(?<=\\?) )/.split(ctx['text']);\n",
    "          ctx['passages'] = new ArrayList();\n",
    "          int i = 0;\n",
    "          boolean remaining = true;\n",
    "          if (envSplit.length == 0) {\n",
    "            return\n",
    "          } else if (envSplit.length == 1) {\n",
    "            Map passage = ['text': envSplit[0]];ctx['passages'].add(passage)\n",
    "          } else {\n",
    "            while (remaining) {\n",
    "              Map passage = ['text': envSplit[i++]];\n",
    "              while (i < envSplit.length && passage.text.length() + envSplit[i].length() < params.model_limit) {passage.text = passage.text + ' ' + envSplit[i++]}\n",
    "              if (i == envSplit.length) {remaining = false}\n",
    "              ctx['passages'].add(passage)\n",
    "            }\n",
    "          }\n",
    "          \"\"\",\n",
    "                \"params\": {\"model_limit\": CHUNK_SIZE},\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"foreach\": {\n",
    "                \"field\": \"passages\",\n",
    "                \"processor\": {\n",
    "                    \"inference\": {\n",
    "                        \"model_id\": MODEL_ID_ES,\n",
    "                        \"input_output\": [\n",
    "                            { \n",
    "                                \"input_field\": \"_ingest._value.text\",\n",
    "                                \"output_field\": \"_ingest._value.vector.predicted_value\"\n",
    "                            }\n",
    "                        ],\n",
    "                        \"on_failure\": [\n",
    "                            {\n",
    "                                \"append\": {\n",
    "                                    \"field\": \"_source._ingest.inference_errors\",\n",
    "                                    \"value\": [\n",
    "                                        {\n",
    "                                            \"message\": \"Processor 'inference' in pipeline 'ml-inference-title-vector' failed with message '{{ _ingest.on_failure_message }}'\",\n",
    "                                            \"pipeline\": \"ml-inference-title-vector\",\n",
    "                                            \"timestamp\": \"{{{ _ingest.timestamp }}}\",\n",
    "                                        }\n",
    "                                    ],\n",
    "                                }\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Index\n",
    "\n",
    "Next step is to prepare the mappings to handle the array of sentences and vector objects that will be created during the ingest pipeline. For this particular text embedding model the dimensions are 384 and dot_product similarity will be used for nearest neighbor calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'es_tripadvisor_nyc_idx'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.delete(index=INDEX_NAME, ignore_unavailable=True)\n",
    "\n",
    "# Setup the index\n",
    "client.indices.create(\n",
    "    index=INDEX_NAME,\n",
    "    settings={\"index\": {\"default_pipeline\": \"chunk_text_to_passages\"}},\n",
    "    mappings={\n",
    "        \"dynamic\": \"true\",\n",
    "        \"properties\": {\n",
    "            \"passages\": {\n",
    "                \"type\": \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"vector\": {\n",
    "                        \"properties\": {\n",
    "                            \"predicted_value\": {\n",
    "                                \"type\": \"dense_vector\",\n",
    "                                \"index\": True,\n",
    "                                \"dims\": MODEL_DIM,\n",
    "                                \"similarity\": MODEL_SIMILARITY,\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some Documents through Celery\n",
    "\n",
    "Now we can add documents with large amounts of text in body_content and automatically have them chunked, and each chunk text embedded into vectors by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510463\n"
     ]
    }
   ],
   "source": [
    "file = '../csv/New_York_reviews.csv'\n",
    "\n",
    "#Read CSV File\n",
    "def read_CSV(csv_file):\n",
    "    csv_rows = []\n",
    "    with open(csv_file) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        fields = reader.fieldnames\n",
    "        fields[0] = '_id'\n",
    "        for row in reader:\n",
    "            new_row = {fields[i]:row[fields[i]] for i in range(len(fields))}\n",
    "            new_row['_index'] = INDEX_NAME\n",
    "            new_row['name'] = new_row.pop('review_id')\n",
    "            new_row['text'] = new_row.pop('review_full')\n",
    "            csv_rows.append(new_row)\n",
    "        return csv_rows\n",
    "\n",
    "docs = read_CSV(file)\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the documents to the index directly\n",
    "for i in range(0, len(docs), ES_CHUNK_SIZE):\n",
    "    ingest_data.apply_async(\n",
    "        kwargs={\n",
    "            \"docs\": docs[i: min(i + ES_CHUNK_SIZE, len(docs))]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Pretty printing Elasticsearch responses\n",
    "\n",
    "Your API calls will return hard-to-read nested JSON. We'll create a little function called pretty_response to return nice, human-readable outputs from our examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_response(response):\n",
    "    if len(response[\"hits\"][\"hits\"]) == 0:\n",
    "        print(\"Your search returned no results.\")\n",
    "    else:\n",
    "        for hit in response[\"hits\"][\"hits\"]:\n",
    "            id = hit[\"_id\"]\n",
    "            score = hit[\"_score\"]\n",
    "            doc_title = hit[\"_source\"][\"name\"]\n",
    "            restaurant_name = hit[\"_source\"][\"restaurant_name\"]\n",
    "            title_review = hit[\"_source\"][\"title_review\"]\n",
    "            passage_text = \"\"\n",
    "\n",
    "            for passage in hit[\"inner_hits\"][\"passages\"][\"hits\"][\"hits\"]:\n",
    "                passage_text += passage[\"fields\"][\"passages\"][0][\"text\"][0] + \"\\n\\n\"\n",
    "\n",
    "            pretty_output = f\"ID: {id}\\nDoc Title: {doc_title}\\nRestaurant Name: {restaurant_name}\\nTitle Review: {title_review}\\nPassage Text:\\n{passage_text}Score: {score}\"\n",
    "            print(pretty_output)\n",
    "            print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making queries\n",
    "\n",
    "To search the data and return what chunk matched the query best you use inner_hits with the knn clause to return just that best matching chunk of the document in the hits output from the query.\n",
    "\n",
    "Below you will see the response which returns the best document and the most relevant passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 32390\n",
      "Doc Title: review_720045084\n",
      "Restaurant Name: Tony_s_Di_Napoli_Midtown\n",
      "Title Review: Fantastic food!\n",
      "Passage Text:\n",
      "The best pasta in New York! Great dessert and friendly staff. A bit noisy on a Sunday evening but a really nice evening close to Times square.\n",
      "\n",
      "Score: 0.9367155\n",
      "---\n",
      "ID: 149\n",
      "Doc Title: review_695311754\n",
      "Restaurant Name: San_Carlo_Osteria_Piemonte\n",
      "Title Review: Outstanding food,  great service and atmosphere \n",
      "Passage Text:\n",
      "I'm a huge fan of picolla cucina on Spring St and I still think they have the best pastas in New York. It's my favorite in NYC, but a block away is San Carlo which may bemy second favorite. It is slightly different in terms of the menu, with less focus on pasta. It also has a slightly larger footprint with a small intimate bar, and has a very good wine and cocktail list.\n",
      "\n",
      "Score: 0.8833201\n",
      "---\n",
      "ID: 21092\n",
      "Doc Title: review_629514788\n",
      "Restaurant Name: IL_Melograno\n",
      "Title Review: Tastefull meal - worth a visit!!\n",
      "Passage Text:\n",
      "Best meal weâ€™ve had in NYC! The pasta was just delicious / super fresh & the staff very friendly and kind. We would recommend it for sure!\n",
      "\n",
      "Score: 0.8786392\n",
      "---\n",
      "ID: 22079\n",
      "Doc Title: review_375834633\n",
      "Restaurant Name: Orso\n",
      "Title Review: Always a crowd pleaser!\n",
      "Passage Text:\n",
      "Love this restaurant and still mourn the closing of the LA spot. The best pastas and a perfect place to have lunch that \"feels\" like NYC! Very traditional and located very near the theater district, so you can hop in for an early dinner pre-show as well. You really can't go wrong ordering everything on the menu but my last visit, I had them make me a simple pasta with tomatoes and basil.\n",
      "\n",
      "Score: 0.8776474\n",
      "---\n",
      "ID: 6697\n",
      "Doc Title: review_140201479\n",
      "Restaurant Name: Marea\n",
      "Title Review: Real pasta in NYC\n",
      "Passage Text:\n",
      "Best italian food in NYc. Good service, friendly and last but not least knowledgeable, which is often very rare in the US ! Great home made pastas, we had a great prepared, fillet of dover sole and one desert was better than the other. Will be back !\n",
      "\n",
      "Score: 0.8699251\n",
      "---\n",
      "ID: 19856\n",
      "Doc Title: review_582275299\n",
      "Restaurant Name: Da_Andrea_Ristorante\n",
      "Title Review: Great Food\n",
      "Passage Text:\n",
      "The food, service and atmosphere was great.  Neighborhood gem and definitely a contender for best pasta in NYC\n",
      "\n",
      "Score: 0.8651651\n",
      "---\n",
      "ID: 31195\n",
      "Doc Title: review_245791186\n",
      "Restaurant Name: Rafele\n",
      "Title Review: Best NYC Restaurant\n",
      "Passage Text:\n",
      "You can't leave NY without visiting this fabulous restaurant!Try the homemade pasta!Great service and place....Love the chef and the host\n",
      "\n",
      "Score: 0.8629388\n",
      "---\n",
      "ID: 16229\n",
      "Doc Title: review_376218168\n",
      "Restaurant Name: Pisticci\n",
      "Title Review: nice place in the Upper West side\n",
      "Passage Text:\n",
      "The restaurant offers well prepared food at a reasonable price. The pasta is the main speciality. It has three large saloons and so it is convenient for large parties. In sum, good service at a reasonable price in NYC.\n",
      "\n",
      "Score: 0.8626459\n",
      "---\n",
      "ID: 14915\n",
      "Doc Title: review_94724860\n",
      "Restaurant Name: Pisticci\n",
      "Title Review: truly italian restaurant\n",
      "Passage Text:\n",
      "It's surprisingly hard to find a good Italian restaurant in New York, given it's huge Italian population. I'm tired of \"Italian-American\" style overcooked pasta drowning in sauce. Thanks God Pisticci gets it right. Their pastas are very simple, but that's the key to Italian cuisine.\n",
      "\n",
      "Score: 0.8612782\n",
      "---\n",
      "ID: 28419\n",
      "Doc Title: review_431712621\n",
      "Restaurant Name: Casa_Barilla\n",
      "Title Review: Average pasta\n",
      "Passage Text:\n",
      "This is a place to visit if you want to eat fast and you don't want a burger. Pastas are OK but it's a kind of a fast-food style cuisine in terms of taste and quality. It's an interesting option in New York from the price perspective.\n",
      "\n",
      "Score: 0.8604957\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "response = client.search(\n",
    "    index=INDEX_NAME,\n",
    "    knn={\n",
    "        \"inner_hits\": {\"size\": 1, \"_source\": False, \"fields\": [\"passages.text\"]},\n",
    "        \"field\": \"passages.vector.predicted_value\",\n",
    "        \"k\": 20,\n",
    "        \"num_candidates\": 100,\n",
    "        \"query_vector_builder\": {\n",
    "            \"text_embedding\": {\n",
    "                \"model_id\": MODEL_ID_ES,\n",
    "                \"model_text\": \"Best pasta in New York\",\n",
    "            }\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "pretty_response(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
